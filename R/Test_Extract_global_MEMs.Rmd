---
title: "Extract data for climate mitigation project"
author: "Julia Blanchard, Camilla Novaglio, Derek Tittensor"
date: "2023-05-18"
output: github_document
editor_options: 
  chunk_output_type: console
---

# The aim of this file is to test extract_global_outputs() by comparing resutls from CN with results from JB + DT 

```{r cars}

rm(list=ls())

### Read in files and extract modelled data at global scale
library(raster)
library(ncdf4)
library(tidyverse)
library(ncdf4.helpers)
library(parallel)
library(pbapply)
library(dplyr, warn.conflicts = FALSE)

select<-dplyr::select 

### using files and code prepared by Cami:

dir<-"/rd/gem/private/users/camillan/EmergentConstraintData"

mem<-c("apecosm","boats", "dbpm", "zoomss", "ecotroph", "macroecological") 
esm<-c("gfdl-esm4", "ipsl-cm6a-lr")
scenario<-c("historical", "ssp126", "ssp585") 

# all file combinations

combinations<-expand.grid(mem = mem, esm = esm, scenario = scenario) %>%
  mutate(resolution = ifelse(mem %in% c("zoomss", "ecotroph", "macroecological"), "annual", "monthly"), 
         year = case_when(
           mem %in% c("boats", "zoomss", "ecotroph", "macroecological") & scenario == "historical" ~ "1950_2014", 
           mem %in% c("apecosm", "dbpm") & scenario == "historical" ~ "1850_2014",
           scenario %in% c("ssp126", "ssp585") ~ "2015_2100"), 
         mem = as.character(mem), 
         esm = as.character(esm), 
         scenario = as.character(scenario),
         netcdf_name = paste0(paste(mem, esm, "nobasd", scenario, "nat_default_tcblog10_global", resolution, year, sep ="_"), ".nc"),
         esm_simpler = ifelse(esm == "ipsl-cm6a-lr", "ipsl","gfdl"),
         identifier = paste(mem, esm_simpler, scenario, sep ="_")) %>% 
  select(-esm_simpler) %>% 
  arrange(mem, esm, scenario)

# apply function in // ----

netcdf = combinations$netcdf_name

# function to be applied (first part of extract_global_outputs())
extract_global_outputsJB<-function(netcdf, file = "new"){
  
  if(file.exists(file.path(dir, netcdf))){
    
    ######### extract info from netcdf name and print warnings ----
    model = sub("\\_.*", "", netcdf)
    
    if(str_detect(netcdf, "gfdl", negate = FALSE)){
      esm = "gfdl-esm4"
    }else if (str_detect(netcdf, "ipsl", negate = FALSE)){
      esm = "ipsl-cm6a-lr"
    }
    
    # WARNING - add in EC? 
    if(str_detect(netcdf, "monthly", negate = FALSE)){
      time_step = "monthly"
    }else if (str_detect(netcdf, "annual", negate = FALSE)){
      time_step = "annual"
    }
    
    if(str_detect(netcdf, "historical", negate = FALSE)){
      scenario = "historical"
    }else if (str_detect(netcdf, "ssp126", negate = FALSE)){
      scenario = "ssp1"
    }else if (str_detect(netcdf, "ssp585", negate = FALSE)){
      scenario = "ssp5"
    }else if (str_detect(netcdf, "picontrol|2100", negate = FALSE)) {
      scenario = "picontrol_fut"
    } else if (str_detect(netcdf, "picontrol|2014", negate = FALSE)) {
      scenario = "picontrol_hist"}
    
    # extract info from netcdf description: 
    nc_data <- nc_open(file.path(dir, netcdf))
    
    lon <- ncvar_get(nc_data, "lon")
    lat <- ncvar_get(nc_data, "lat", verbose = F)
    t <- as.character(nc.get.time.series(nc_data))
    
    # this is only to FIX zoom size bins names 
    if(model != "zoomss" & file == "new"){
      bins<-ncvar_get(nc_data, "bins")
    }else if (model != "zoomss" & file == "old"){ # this is only to check DBPM old files (not in DKRZ)
      bins<-ncvar_get(nc_data, "size")
    }else if (model == "zoomss"){
      bins<-c(1:6)}
    
    t_units<-ncatt_get(nc_data, "time", "units")$value
    b_units<-ncatt_get(nc_data, "tcblog10", "units")$value
    
    nc_close(nc_data)
    
    # extract data as raster object: 
    brick_data<-list()
    
    for (i in 1:length(bins)){
      brick_data[[i]]<-brick(file.path(dir, netcdf), level = i)
      print(dim(brick_data[[i]]))
    }
    
    # # check 
    # plot(brick_data[[1]][[1]])
    # mean(brick_data[[1]]) # BOATS size class 1 and 6 is a matrix of NAs
    
    return(brick_data) # end here - use the first part of function in Extract_SoutherOcean repo
    
  }
  }    

# now do all:
all_bricks<-pblapply(netcdf,extract_global_outputsJB,cl=detectCores()-2)

#-------------------------------------------------------------------------------
# JB version 

# multiply each grid cell value by cell area and sum over all grid cells.
#to multiply by area,  need to convert area from km2 to m2 (*1e6), and sum over all cells each month.

bricktotime <-function(br=1,all_bricks,lyr=1,month=1){
  monthend<-dim(all_bricks[[br]][[lyr]])[3]
  lyrend<-length(lengths(all_bricks[[br]]))
  bricksum<-matrix(NA,nrow=monthend,ncol=lyrend)
  for(elyr in lyr:lyrend){
      bricksum[,elyr]<-cellStats(all_bricks[[br]][[elyr]][[month:monthend]]*area(all_bricks[[br]][[elyr]][[month:monthend]])*1e6,sum)
  }
  return(bricksum)
}

whichones<-rep(NA,36)
for (i in 1:36) whichones[i]<-length(all_bricks[[i]])
bricklist<-which(whichones>0)

non_empties<-Filter(Negate(is.null),all_bricks)

# CN this sums across lat/lon and considers grid cell area but results are still monthly and size-resolved. 
all_bricksums<-pblapply(1:length(non_empties),bricktotime,all_bricks=non_empties,cl=26)

filenames<-netcdf[bricklist] 

saveRDS(all_bricksums,"/home/ubuntu/climate_mitigation/Tmp_data/Test_TotalBiomassinSizeBinsbyModelRun.RDS")

saveRDS(filenames,"/home/ubuntu/climate_mitigation/Tmp_data/Test_FilenamesTotalBiomassinSizeBinsbyModelRun.RDS")
 
#-------------------------------------------------------------------------------
# CN with Julia's data - sum biomass across size class and average across months to check you get consistent results with Derek's plot and then with CN analyses

rm(list=ls())

TotalBiomassinSizeBinsbyModelRun<-readRDS("/home/ubuntu/climate_mitigation/Tmp_data/Test_TotalBiomassinSizeBinsbyModelRun.RDS")
FilenamesTotalBiomassinSizeBinsbyModelRun<-readRDS("/home/ubuntu/climate_mitigation/Tmp_data/Test_FilenamesTotalBiomassinSizeBinsbyModelRun.RDS")

# # Check JB old outputs - different, possibly something wrong in function used?
# TotalBiomassinSizeBinsbyModelRun<-readRDS("/home/ubuntu/climate_mitigation/Tmp_data/TotalBiomassinSizeBinsbyModelRun.RDS")
# FilenamesTotalBiomassinSizeBinsbyModelRun<-readRDS("/home/ubuntu/climate_mitigation/Tmp_data/FilenamesTotalBiomassinSizeBinsbyModelRun.RDS")

# take apecosm as example: 
trial<-as.data.frame(TotalBiomassinSizeBinsbyModelRun[[1]])
time<-seq(as.Date("1850-01-01"), as.Date("2014-12-31"), by="month")

new_data<-cbind(time, trial)
new_data<-new_data %>% 
  filter(time >= "1950-01-01") %>% 
  gather(key = size, value = biomass, -time) %>% 
  dplyr::filter(size %in% c("V2", "V3", "V4", "V5")) %>% # consider bins 2 to 5
  group_by(time) %>% 
  summarise(biomass = sum(biomass)) %>% # sum across size classes 
  ungroup() %>% 
  mutate(year = format(as.Date(time, format="%Y-%m-%d"),"%Y")) %>% 
  group_by(year) %>% # mean across months 
  summarise(biomass = mean(biomass)) %>% 
  ungroup() 

new_data$year<-as.numeric(new_data$year)

# OK this seems to be the same as yours... 
plot<-ggplot(new_data, aes(x = year, y = biomass))+
  geom_line()

plot

jpeg("/home/ubuntu/climate_mitigation/Output/test_apecosm_JBcode.jpg", width = 7, height = 5, units = "in", res = 300, bg = "transparent")
plot
dev.off()

# jpeg("/home/ubuntu/climate_mitigation/Output/test_apecosm_JBcode_withOldData.jpg", width = 7, height = 5, units = "in", res = 300, bg = "transparent")
# plot
# dev.off()

#-------------------------------------------------------------------------------
# DT version 

rm(list=ls())
mem<-c("apecosm","boats", "dbpm", "zoomss", "ecotroph", "macroecological") 
esm<-c("gfdl-esm4", "ipsl-cm6a-lr")
scenario<-c("historical", "ssp126", "ssp585") 

TotalBiomassinSizeBinsbyModelRun<-readRDS("/home/ubuntu/climate_mitigation/Tmp_data/Test_TotalBiomassinSizeBinsbyModelRun.RDS")
FilenamesTotalBiomassinSizeBinsbyModelRun<-readRDS("/home/ubuntu/climate_mitigation/Tmp_data/Test_FilenamesTotalBiomassinSizeBinsbyModelRun.RDS")

# # Check with JB old outputs
# TotalBiomassinSizeBinsbyModelRun<-readRDS("/home/ubuntu/climate_mitigation/Tmp_data/Test_TotalBiomassinSizeBinsbyModelRun.RDS")
# FilenamesTotalBiomassinSizeBinsbyModelRun<-readRDS("/home/ubuntu/climate_mitigation/Tmp_data/Test_FilenamesTotalBiomassinSizeBinsbyModelRun.RDS")

# Save the data in the format required for the project

# Extract the appropriate size bins
# For size-structure models these should be: 1-10g, 10-100g, 100g-1kg, 1-10kg, 10-100kg, >100kg
# But note that models may have different bins

# Mem_bins should contain the number of size bins provided by each model
# AT PRESENT THIS IS JUST DUMMY/TEST DATA
mem_bins = list(apecosm = 6, boats = 4, dbpm = 6, zoomss = 6, ecotroph = 6, macroecological = 5)

# Mem_bins_to_use indicates the size bins that represent 10g - 100kg for each model
# AT PRESENT THIS IS JUST DUMMY/TEST DATA
mem_bins_to_use = list(apecosm = 2:5, boats = 2:5, dbpm = 2:5, zoomss = 2:5, ecotroph = 2:5, macroecological = 2:5)

if (!identical(mem, names(mem_bins)))
  print("Your mem names and list of bins for each mem do not match")

if (!identical(mem, names(mem_bins_to_use)))
  print("Your mem names and list of bins for each mem do not match")

# Set the reference period for each model
reference_period_min_year = 1995
reference_period_max_year = 2014

# Data frame to hold model size-summed outputs
size_summed_outputs = data.frame("climate_model" = NA, "impact_model"= NA, "forcing"= NA, "time"= NA, "biomass"= NA)

data_frame_start = 1
for (ii in 1:length(mem))
{
  ii = 1 # CN check apecosm ipsl historical as per above  
  for (jj in 1:length(esm))
  {
    jj = 2
    for (kk in 1:length(scenario))
    {
      kk = 1
      
      # Identify the specific model run
      mem_model = which(FilenamesTotalBiomassinSizeBinsbyModelRun %in% str_subset(FilenamesTotalBiomassinSizeBinsbyModelRun, mem[ii]))
      esm_model = which(FilenamesTotalBiomassinSizeBinsbyModelRun %in% str_subset(FilenamesTotalBiomassinSizeBinsbyModelRun, esm[jj]))
      scenario_run = which(FilenamesTotalBiomassinSizeBinsbyModelRun %in% str_subset(FilenamesTotalBiomassinSizeBinsbyModelRun, scenario[kk]))
      
      filename_to_use = Reduce(intersect, list(mem_model, esm_model, scenario_run))
      if ((length(filename_to_use) == 0) || (length(filename_to_use) >1))
      {
        print("Error when selecting file: either this model/esm/scenario combination was not used, or there are more than one files that match")
        print(paste(mem[ii], esm[jj], scenario[kk], sep = " "))
      } else
      {
        # Extract the data in the appropriate size bin(s)
        min_years = c("1850","1950","2015")
        max_years = c("2014","2100")
        min_year = min(as.numeric(min_years[which(sapply(min_years, grepl, FilenamesTotalBiomassinSizeBinsbyModelRun[filename_to_use]) == TRUE)]))
        max_year = max(as.numeric(max_years[which(sapply(max_years, grepl, FilenamesTotalBiomassinSizeBinsbyModelRun[filename_to_use]) == TRUE)]))
        
        print(paste(mem[ii], esm[jj], scenario[kk], sep = " "))
             
        total_bins_this_model = eval(parse(text = paste("mem_bins$",mem[ii],sep="")))
        bins_to_use_this_model = eval(parse(text = paste("mem_bins_to_use$",mem[ii],sep="")))
        
        print(paste("Total size bins for this model: ", total_bins_this_model))
        print("Bins to use for this model:")
        print(bins_to_use_this_model)
        
        for (ll in data_frame_start:(data_frame_start + (max_year - min_year))) # CN for all years 
        {
          # trial 
          # ll =1
          
          # build the dataframe: 
          size_summed_outputs[ll,1] = esm[jj] # column 1 = esm 
          size_summed_outputs[ll,2] = mem[ii] # column 2 = mem
          size_summed_outputs[ll,3] = scenario[kk] # column 3 scenarios
          size_summed_outputs[ll,4] = min_year + ll - 1 # column 4 year
          size_summed_outputs[ll,5] = sum(TotalBiomassinSizeBinsbyModelRun[[filename_to_use]][(ll - 1) * total_bins_this_model + (1:total_bins_this_model)][bins_to_use_this_model]) # column 5 sum of values across bins (outputs is still monthly but here we are looping through years ... )
          
          # 
          # ### CN check the line above by doing step by step
          # a<-TotalBiomassinSizeBinsbyModelRun[[filename_to_use]]
          # b<-(ll - 1) * total_bins_this_model + (1:total_bins_this_model) # define position of biomass values to consider in matrix
          # c<-bins_to_use_this_model
          # a[b][c] # the 4 monthly values ...
          # # if ll = 1: 
          # # [1] 3.271494e-07 7.797768e-07 1.637883e-06 3.212845e-06
          # 
          # # for year 1 and month 1 this should be:
          # dim(TotalBiomassinSizeBinsbyModelRun[[1]])
          # TotalBiomassinSizeBinsbyModelRun[[1]][ll,]
          # # [1] 8.884711e-08 2.303387e-25 2.357597e-24 2.329401e-23 2.537454e-22 2.201534e-21
          # 
          # # discrepancy might be consideration of 4 elements of first column instead of first row?
          # TotalBiomassinSizeBinsbyModelRun[[1]][b,]
          # # [1] 8.884711e-08 3.271494e-07 7.797768e-07 1.637883e-06 3.212845e-06 6.095231e-06
          # 
          # # if we adjust to the below
          # TotalBiomassinSizeBinsbyModelRun[[1]][ll,b][c]
         }
        data_frame_start = ll + 1
      }
    }
  }
}

# CN reproduce DT's plot to check yours 
plot<-ggplot(size_summed_outputs, aes(x = time, y = biomass))+
  geom_line()

plot

# same as provided by DT but different from approach above and CN results - see inside loop above for possible reason. The difference could also be because some models provide monthly that have not been averaged to annual in script above but the loop annual outputs for all models.  

jpeg("/home/ubuntu/climate_mitigation/Output/test_apecosm_DTcode.jpg", width = 7, height = 5, units = "in", res = 300, bg = "transparent")
plot
dev.off()

# # this plot with new or old data is the same
# jpeg("/home/ubuntu/climate_mitigation/Output/test_apecosm_DTcode_withOldData.jpg", width = 7, height = 5, units = "in", res = 300, bg = "transparent")
# plot
# dev.off()


```


