---
title: "Extract data for climate mitigation project"
author: "Julia Blanchard, Camilla Novaglio, Derek Tittensor"
date: "2023-05-18"
output: github_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Aim

This script is for extracting FishMIP global marine ecosystem model outputs for use in a cross-sectoral climate mitigation paper being led by Christoph Semken.

For this project we need th global time series of biomass outputs, spanning size ranges typical of exploited fishes - 10g to 1000 kg.

We will calculate annual time series spanning 1850-2100 under the rcp8.5 and rcp2.6 scenarios for each of the models, for whihc outputs are available:

APECOSM  - available, IPSL only
BOATS  - available
DBEM  - possible later to request OR possible using Lmax classes?
DBPM - available
EcoOcean  - possible using Lmax classes?
EcoTroph  - available?
FEISTY  - possible using Lmax classes?
MACROECOLOGICAL  - available
ZooMSS - available

## File dowload 

check FishMIP/EmergentConstraints repo R/01_extract_modelled_data.Rmd for details and notes. 

download macroecological (hist was dowloaded for SO project)

scp -r b381217@levante.dkrz.de:/work/bb0820/ISIMIP/ISIMIP3b/OutputData/marine-fishery_global/MACROECOLOGICAL/ipsl-cm6a-lr/future/*nat_default_tcblog10* /rd/gem/private/users/camillan/EmergentConstraintData/

scp -r b381217@levante.dkrz.de:/work/bb0820/ISIMIP/ISIMIP3b/OutputData/marine-fishery_global/MACROECOLOGICAL/gfdl-esm4/future/*nat_default_tcblog10* /rd/gem/private/users/camillan/EmergentConstraintData/ 

All models include 6 bins, except for boats and macroecological. Boats include 2-5 (with 1 and 6 being present but empty) and macroecological includes bins 1 to 5. Sums across layers are calculated using bins 2 to 5, minimum common denominator.

## Set environment 

```{r cars}

rm(list=ls())

### Read in files and extract modelled data at global scale
library(raster)
library(ncdf4)
library(tidyverse)
library(ncdf4.helpers)
library(parallel)
library(pbapply)
library(dplyr, warn.conflicts = FALSE)

```

## Read in files and extract modelled data at global scale

```{r}

### using files and code prepared by Cami:

dir<-"/rd/gem/private/users/camillan/EmergentConstraintData"

mem<-c("apecosm","boats", "dbpm", "zoomss", "ecotroph", "macroecological") 
esm<-c("gfdl-esm4", "ipsl-cm6a-lr")
scenario<-c("historical", "ssp126", "ssp585") 

# all file combinations

combinations<-expand.grid(mem = mem, esm = esm, scenario = scenario) %>%
  mutate(resolution = ifelse(mem %in% c("zoomss", "ecotroph", "macroecological"), "annual", "monthly"), 
         year = case_when(
           mem %in% c("boats", "zoomss", "ecotroph", "macroecological") & scenario == "historical" ~ "1950_2014", 
           mem %in% c("apecosm", "dbpm") & scenario == "historical" ~ "1850_2014",
           scenario %in% c("ssp126", "ssp585") ~ "2015_2100"), 
         mem = as.character(mem), 
         esm = as.character(esm), 
         scenario = as.character(scenario),
         netcdf_name = paste0(paste(mem, esm, "nobasd", scenario, "nat_default_tcblog10_global", resolution, year, sep ="_"), ".nc"),
         esm_simpler = ifelse(esm == "ipsl-cm6a-lr", "ipsl","gfdl"),
         identifier = paste(mem, esm_simpler, scenario, sep ="_")) %>% 
  select(-esm_simpler) %>% 
  arrange(mem, esm, scenario)

# apply function in // ----

netcdf = combinations$netcdf_name

source("/home/ubuntu/climate_mitigation/R/Helper_functions_mitigation.R")

# # test function 
# test<-extract_global_outputs(netcdf[4]) 
# 
# # check
# test$brick_data_annual
# plot(test$brick_data_annual[[5]][[10]]) # size bin 5, random time step
# 
# rm(test)

# now do all:
all_bricks<-pblapply(netcdf,extract_global_outputs,cl=detectCores()-2)

# extract data from function object
names(all_bricks) <- combinations$identifier

# annual maps as raster objects
brick_data_annual<-sapply(all_bricks, function(x) x[["brick_data_annual"]])
brick_data_annual[sapply(brick_data_annual, is.null)] <- NULL # remove empty objects

# # check
# names(brick_data_annual)
# brick_data_annual$boats_gfdl_historical[[3]][[1]]
# plot(brick_data_annual$boats_gfdl_historical[[3]][[1]])

# annual trend in biomass at size bins level, for each MEM, ESM and scenario combination
SumsBySizeBins_df<-sapply(all_bricks, function(x) x[["SumsBySizeBins_df"]])
SumsBySizeBins_df[sapply(SumsBySizeBins_df, is.null)] <- NULL

# # check
# SumsBySizeBins_df$boats_gfdl_historical

# adjust dataset: 
SumsBySizeBins_df<-do.call(rbind, SumsBySizeBins_df)
rownames(SumsBySizeBins_df)<-NULL
SumsBySizeBins_df<-SumsBySizeBins_df %>% 
  select(Year,scenario, esm, mem, bin, weighted_mean) %>% 
  rename(year = Year, biomass = weighted_mean)
  
head(SumsBySizeBins_df)

# annual trend in total biomass (sum across size bins 2 to 5), for each MEM, ESM and scenario combination
SumsAllBio_df<-sapply(all_bricks, function(x) x[["SumsAllBio_df"]])
SumsAllBio_df[sapply(SumsAllBio_df, is.null)] <- NULL

# # check
# SumsAllBio_df$boats_gfdl_historical

# adjust dataset: 
SumsAllBio_df<-do.call(rbind, SumsAllBio_df)
rownames(SumsAllBio_df)<-NULL
SumsAllBio_df<-SumsAllBio_df %>% 
  select(Year,scenario, esm, mem, weighted_mean_allBio) %>% 
  rename(year = Year, biomass = weighted_mean_allBio)
  
head(SumsAllBio_df)

```

## save data as temp_file 

```{r}

# Extract_global_MEMs_allBins.RData = bins 1 to 6 considered 
# Extract_global_MEMs.RData = bins 2 to 5 considered

save(brick_data_annual,
     SumsBySizeBins_df,
     SumsAllBio_df,
     file = "/home/ubuntu/climate_mitigation/Tmp_data/Extract_global_MEMs_allBins.RData")

```

## check outputs 

```{r}

rm(list=ls())
data<-"/home/ubuntu/climate_mitigation/Tmp_data/Extract_global_MEMs_allBins.RData"
data<-"/home/ubuntu/climate_mitigation/Tmp_data/Extract_global_MEMs.RData"
load(data)

SumsBySizeBins_df_toplot<-SumsBySizeBins_df %>% 
  filter(mem == "apecosm", esm == "ipsl-cm6a-lr")

plot<-ggplot(SumsBySizeBins_df_toplot, aes(x = year, y = biomass, group = scenario, color = scenario))+
  geom_line()+
  facet_wrap(~bin, scale = "free")

# plot all 
SumsBySizeBins_df_toplot2<- SumsBySizeBins_df %>% 
  mutate(ID = paste(esm, bin, scenario, sep ="_"))

plot<-ggplot(SumsBySizeBins_df_toplot2, aes(x = year, y = biomass, group = ID, color = scenario))+
  geom_line()+
  facet_wrap(~mem)

jpeg("/home/ubuntu/climate_mitigation/Output/trends_allModels_allBinsSeparately.jpg", width = 7, height = 5, units = "in", res = 300, bg = "transparent")
plot
dev.off()

# plot biomass tot 
SumsAllBio_df_toplot<- SumsAllBio_df %>% 
  mutate(ID = paste(esm, scenario, sep ="_"))

plot<-ggplot(SumsAllBio_df_toplot, aes(x = year, y = biomass, group = ID, color = scenario))+
  geom_line()+
  facet_wrap(~mem, scale = "free")

jpeg("/home/ubuntu/climate_mitigation/Output/trends_allModels_allBinsSummed.jpg", width = 7, height = 5, units = "in", res = 300, bg = "transparent")
plot
dev.off()

plot<-ggplot(filter(SumsAllBio_df_toplot, mem == "apecosm"), aes(x = year, y = biomass, group = ID, color = scenario))+
  geom_line()

jpeg("/home/ubuntu/climate_mitigation/Output/trends_apecosm_allBinsSeparately.jpg", width = 7, height = 5, units = "in", res = 300, bg = "transparent")
plot
dev.off()

## plot maps of values 
plot(brick_data_annual$dbpm_ipsl_historical[[1]][[1]])
plot(brick_data_annual$apecosm_ipsl_historical[[1]][[1]])

```

### Julia an Derek version on a function above that 

```{r}
#multiply each grid cell value by cell area and sum over all grid cells.
#to multiply by area,  need to convert area from km2 to m2 (*1e6), and sum over all cells each month.

# # JB version using half cami's function 

bricktotime <-function(br=1,all_bricks,lyr=1,month=1){
  monthend<-dim(all_bricks[[br]][[lyr]])[3]
  lyrend<-length(lengths(all_bricks[[br]]))
  bricksum<-matrix(NA,nrow=monthend,ncol=lyrend)
  for(elyr in lyr:lyrend){
      bricksum[,elyr]<-cellStats(all_bricks[[br]][[elyr]][[month:monthend]]*area(all_bricks[[br]][[elyr]][[month:monthend]])*1e6,sum)
  }
  return(bricksum)
}

whichones<-rep(NA,36)
for (i in 1:36) whichones[i]<-length(all_bricks[[i]])
bricklist<-which(whichones>0)

# mylist <- all_bricks %>% 
# purrr::map(`[`,bricklist) 

non_empties<-Filter(Negate(is.null),all_bricks)

#all_bricksums<-list(1:length(non_empties))

# for (i in 1:2){
#  all_bricksums[[i]]<-bricktotime(i,all_bricks=non_empties)
#  }

all_bricksums<-pblapply(1:length(non_empties),bricktotime,all_bricks=non_empties,cl=26)

filenames<-netcdf[bricklist] 

saveRDS(all_bricksums,"TotalBiomassinSizeBinsbyModelRun.RDS")

saveRDS(filenames,"FilenamesTotalBiomassinSizeBinsbyModelRun.RDS")
 
#-------------------------------------------------------------------------------
## CN check that you get the same results if you use julia's approach 
# use apecosm as example # WARNING - I cannot reproduce Derek's nor my plot !!!! 

TotalBiomassinSizeBinsbyModelRun<-readRDS("TotalBiomassinSizeBinsbyModelRun.RDS")
trial<-TotalBiomassinSizeBinsbyModelRun[[1]]
dim(trial)
class(trial)
trial<-as.data.frame(trial)
head(trial)
nrow(trial)

time<-seq(as.Date("1850-01-01"), as.Date("2014-12-31"), by="month")
# time<-format(as.Date(time, format="%Y-%m-%d"),"%Y")
# year = as.numeric(time)
# length(time)

new_data<-cbind(time, trial)
head(new_data)
# library(tidyverse)
new_data<-new_data %>% 
  gather(key = size, value = biomass, -time)
head(new_data)

str(new_data)

new_data<-new_data %>% 
  dplyr::filter(size %in% c("V2", "V3", "V4", "V5")) %>% 
  group_by(time) %>% 
  summarise(biomass = sum(biomass)) %>% 
  ungroup() 

new_data2<-new_data %>% 
  mutate(year = format(as.Date(time, format="%Y-%m-%d"),"%Y")) %>% 
  group_by(year) %>% 
  summarise(biomass = mean(biomass)) %>% 
  ungroup() 

str(new_data2)

new_data2$year<-as.numeric(new_data2$year)

head(new_data2)
ggplot(new_data2, aes(x = year, y = biomass))+
  geom_line()

#-------------------------------------------------------------------------------
## DT version 

## CN trial 
rm(list=ls())
# trial # CN using RDS from Julia
mem<-c("apecosm","boats", "dbpm", "zoomss", "ecotroph", "macroecological") 
esm<-c("gfdl-esm4", "ipsl-cm6a-lr")
scenario<-c("historical", "ssp126", "ssp585") 
TotalBiomassinSizeBinsbyModelRun<-readRDS("TotalBiomassinSizeBinsbyModelRun.RDS")
FilenamesTotalBiomassinSizeBinsbyModelRun<-readRDS("FilenamesTotalBiomassinSizeBinsbyModelRun.RDS")

# Save the data in the format required for the project

# Extract the appropriate size bins
# For size-structure models these should be: 1-10g, 10-100g, 100g-1kg, 1-10kg, 10-100kg, >100kg
# But note that models may have different bins

# Mem_bins should contain the number of size bins provided by each model
# AT PRESENT THIS IS JUST DUMMY/TEST DATA
mem_bins = list(apecosm = 6, boats = 6, dbpm = 6, zoomss = 5, ecotroph = 6, macroecological = 5)

# Mem_bins_to_use indicates the size bins that represent 10g - 100kg for each model
# AT PRESENT THIS IS JUST DUMMY/TEST DATA
mem_bins_to_use = list(apecosm = 1:6, boats = 2:5, dbpm = 1:6, zoomss = 1:6, ecotroph = 1:6, macroecological = 1:5)

if (!identical(mem, names(mem_bins)))
  print("Your mem names and list of bins for each mem do not match")

if (!identical(mem, names(mem_bins_to_use)))
  print("Your mem names and list of bins for each mem do not match")

# Set the reference period for each model
reference_period_min_year = 1995
reference_period_max_year = 2014

# Data frame to hold model size-summed outputs
size_summed_outputs = data.frame("climate_model" = NA, "impact_model"= NA, "forcing"= NA, "time"= NA, "biomass"= NA)

data_frame_start = 1
for (ii in 1:length(mem))
{
  ii = 1
  for (jj in 1:length(esm))
  {
    jj = 2
    for (kk in 1:length(scenario))
    {
      kk = 1
      
      # Identify the specific model run
      mem_model = which(FilenamesTotalBiomassinSizeBinsbyModelRun %in% str_subset(FilenamesTotalBiomassinSizeBinsbyModelRun, mem[ii]))
      esm_model = which(FilenamesTotalBiomassinSizeBinsbyModelRun %in% str_subset(FilenamesTotalBiomassinSizeBinsbyModelRun, esm[jj]))
      scenario_run = which(FilenamesTotalBiomassinSizeBinsbyModelRun %in% str_subset(FilenamesTotalBiomassinSizeBinsbyModelRun, scenario[kk]))
      
      filename_to_use = Reduce(intersect, list(mem_model, esm_model, scenario_run))
      if ((length(filename_to_use) == 0) || (length(filename_to_use) >1))
      {
        print("Error when selecting file: either this model/esm/scenario combination was not used, or there are more than one files that match")
        print(paste(mem[ii], esm[jj], scenario[kk], sep = " "))
      } else
      {
        # Extract the data in the appropriate size bin(s)
        min_years = c("1850","1950","2015")
        max_years = c("2014","2100")
        min_year = min(as.numeric(min_years[which(sapply(min_years, grepl, FilenamesTotalBiomassinSizeBinsbyModelRun[filename_to_use]) == TRUE)]))
        max_year = max(as.numeric(max_years[which(sapply(max_years, grepl, FilenamesTotalBiomassinSizeBinsbyModelRun[filename_to_use]) == TRUE)]))
        
        print(paste(mem[ii], esm[jj], scenario[kk], sep = " "))
             
        total_bins_this_model = eval(parse(text = paste("mem_bins$",mem[ii],sep="")))
        bins_to_use_this_model = eval(parse(text = paste("mem_bins_to_use$",mem[ii],sep="")))
        
        print(paste("Total size bins for this model: ", total_bins_this_model))
        print("Bins to use for this model:")
        print(bins_to_use_this_model)
        
        for (ll in data_frame_start:(data_frame_start + (max_year - min_year)))
        {
          size_summed_outputs[ll,1] = esm[jj]
          size_summed_outputs[ll,2] = mem[ii]
          size_summed_outputs[ll,3] = scenario[kk]
          size_summed_outputs[ll,4] = min_year + ll - 1
          size_summed_outputs[ll,5] = sum(TotalBiomassinSizeBinsbyModelRun[[filename_to_use]][(ll - 1) * total_bins_this_model + (1:total_bins_this_model)][bins_to_use_this_model])
        }
        data_frame_start = ll + 1
      }
    }
  }
}

# CN reproduce Derek's plot to check yours - not possible... 
# is this the same as the one you produce when considering all size bins? no  
unique(size_summed_outputs$time)
size_summed_outputs<-size_summed_outputs %>% 
  filter(time <=2014)
ggplot(size_summed_outputs, aes(x = time, y = biomass))+
  geom_line()

# Now need to put into the format for the marginal impact project; see the pdf that they sent. Needs to be a damage function that is compared to a baseline period

```


